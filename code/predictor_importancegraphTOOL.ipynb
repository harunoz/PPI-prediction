{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS A TOOL WHICH I FOUND ONLINE, IT HELPS TO GRAPH PREDICTOR IMPORTANCE AND INFORMATION ABOUT OTHER FEATURES\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, cohen_kappa_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve, SCORERS\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.externals import joblib\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "print('Operating system version....', platform.platform())\n",
    "print(\"Python version is........... %s.%s.%s\" % sys.version_info[:3])\n",
    "print('scikit-learn version is.....', sklearn.__version__)\n",
    "print('pandas version is...........', pd.__version__)\n",
    "print('numpy version is............', np.__version__)\n",
    "print('matplotlib version is.......', matplotlib.__version__)\n",
    "\n",
    "\n",
    "def Correlation_plot(df):\n",
    "    plt.ioff()\n",
    "    red_green = [\"#ff0000\", \"#00ff00\"]\n",
    "    sns.set_palette(red_green)\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    g = sns.pairplot(df,\n",
    "                     diag_kind = 'kde',\n",
    "                     hue = \"feature_type\",\n",
    "                     markers = [\"o\", \"D\"],\n",
    "                     size = 1.5,\n",
    "                     aspect = 1,\n",
    "                     plot_kws = {\"s\": 6})\n",
    "    g.fig.subplots_adjust(right = 0.9)\n",
    "    plt.show()\n",
    "\n",
    "def LoadData():\n",
    "    global X_train, y_train, X_test, y_test, train, test \n",
    "    global feature_columns, response_column, n_features\n",
    "    \n",
    "    model_full = pd.read_csv(\"newclass.csv\")\n",
    "    model_full= model_full.select_dtypes(include=np.number)\n",
    "    x = model_full[model_full.columns[np.concatenate([range(70,79)])]]\n",
    "    y = model_full.iloc[:,2:3:]\n",
    "    \n",
    "    feature_columns = ['Template_sequence_identity', 'Alignment_score',\n",
    "       'Interactor_template_sequence_identity', 'Interactor_alignment_score',\n",
    "       'Model/DOPE_score', 'Matrix_score', 'Solvent_accessibility_wt',\n",
    "       'Solvent_accessibility_mut', 'pcv_salt_equal_wt',\n",
    "       'pcv_salt_opposite_wt', 'pcv_hbond_wt', 'pcv_vdW_wt',\n",
    "       'pcv_salt_equal_mut', 'pcv_salt_opposite_mut', 'pcv_hbond_mut',\n",
    "       'pcv_vdW_mut', 'pcv_salt_equal_self_wt', 'pcv_salt_opposite_self_wt',\n",
    "       'pcv_hbond_self_wt', 'pcv_vdW_self_wt', 'pcv_salt_equal_self_mut',\n",
    "       'pcv_salt_opposite_self_mut', 'pcv_hbond_self_mut', 'pcv_vdW_self_mut',\n",
    "       'dg_wt', 'backbone_hbond_wt', 'sidechain_hbond_wt', 'van_der_waals_wt',\n",
    "       'electrostatics_wt', 'solvation_polar_wt', 'solvation_hydrophobic_wt',\n",
    "       'van_der_waals_clashes_wt', 'entropy_sidechain_wt',\n",
    "       'entropy_mainchain_wt', 'sloop_entropy_wt', 'mloop_entropy_wt',\n",
    "       'cis_bond_wt', 'torsional_clash_wt', 'backbone_clash_wt',\n",
    "       'helix_dipole_wt', 'water_bridge_wt', 'disulfide_wt',\n",
    "       'electrostatic_kon_wt', 'partial_covalent_bonds_wt',\n",
    "       'energy_ionisation_wt', 'entropy_complex_wt', 'number_of_residues_wt',\n",
    "       'dg_mut', 'backbone_hbond_mut', 'sidechain_hbond_mut',\n",
    "       'van_der_waals_mut', 'electrostatics_mut', 'solvation_polar_mut',\n",
    "       'solvation_hydrophobic_mut', 'van_der_waals_clashes_mut',\n",
    "       'entropy_sidechain_mut', 'entropy_mainchain_mut', 'sloop_entropy_mut',\n",
    "       'mloop_entropy_mut', 'cis_bond_mut', 'torsional_clash_mut',\n",
    "       'backbone_clash_mut', 'helix_dipole_mut', 'water_bridge_mut',\n",
    "       'disulfide_mut', 'electrostatic_kon_mut', 'partial_covalent_bonds_mut',\n",
    "       'energy_ionisation_mut', 'entropy_complex_mut',\n",
    "       'number_of_residues_mut', 'IntraclashesEnergy1_wt',\n",
    "       'IntraclashesEnergy1_mut', 'IntraclashesEnergy2_wt',\n",
    "       'IntraclashesEnergy2_mut', 'Interface_contact_distance_wt',\n",
    "       'Interface_contact_distance_mut']\n",
    "    response_column = ['feature_type']\n",
    "\n",
    "\n",
    "    n_features = 76\n",
    "    mask = feature_columns + response_column\n",
    "    \n",
    "    model = model_full[mask]\n",
    "    print('Model dataset:\\n', model.head(5))\n",
    "    print('\\nDescription of model dataset:\\n', model[feature_columns].describe(include='all'))\n",
    "     \n",
    "    Correlation_plot(model)\n",
    "\n",
    "    # Split the data into Train and Test with Train having 80% and test 20% each\n",
    "    train_full, test_full = np.split(model_full.sample(frac=1), [int(.8*len(model))])\n",
    "\n",
    "    X_train  = train_full[feature_columns].as_matrix()\n",
    "    y_train_ = train_full[response_column].as_matrix()\n",
    "    X_test   = test_full[feature_columns].as_matrix()\n",
    "    y_test_  = test_full[response_column].as_matrix()\n",
    "    \n",
    "    y_train = np.reshape(y_train_, len(y_train_))\n",
    "    y_test  = np.reshape(y_test_,  len(y_test_))\n",
    "    \n",
    "    train = train_full[mask]\n",
    "    test  = test_full[mask]\n",
    "    print('Shape of train: ', train.shape)\n",
    "    print('Shape of test:  ', test.shape)\n",
    "    return\n",
    "def ROC_Curve(rf, auc):\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    rf_fit = rf.fit(X_train, y_train)\n",
    "    fit = one_hot_encoder.fit(rf.apply(X_train))\n",
    "    y_predicted = rf.predict_proba(X_test)[:, 1]\n",
    "    false_positive, true_positive, _ = roc_curve(y_test, y_predicted)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(false_positive, true_positive, color='darkorange', label='Random Forest')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve (area = %0.2f)' % auc)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "def Print_Metrics(saved_rf):\n",
    "    print('\\nModel performance on the test data set:')\n",
    "\n",
    "    # print('Train Accuracy.......', accuracy_score(y_train, best_model.predict(X_train)))\n",
    "    # print('Validate Accuracy....', accuracy_score(y_valid, best_model.predict(X_valid)))\n",
    "\n",
    "    y_predict_test  = best_model.predict(X_test)\n",
    "    mse             = metrics.mean_squared_error(y_test, y_predict_test)\n",
    "    logloss_test    = metrics.log_loss(y_test, y_predict_test)\n",
    "    accuracy_test   = metrics.accuracy_score(y_test, y_predict_test)\n",
    "    accuracy_test2  = best_model.score(X_test, y_test)\n",
    "    F1_test         = metrics.f1_score(y_test, y_predict_test)\n",
    "    precision_test  = precision_score(y_test, y_predict_test, average='binary')\n",
    "    precision_test2 = metrics.precision_score(y_test, y_predict_test)\n",
    "    recall_test     = recall_score(y_test, y_predict_test, average='binary')\n",
    "    auc_test        = metrics.roc_auc_score(y_test, y_predict_test)\n",
    "    r2_test         = metrics.r2_score(y_test, y_predict_test)\n",
    "   \n",
    "    #test_auc       = h2o.get_model(\"best_rf\").model_performance(test_data=test).auc()\n",
    "    #print('Best model performance based on auc: ', test_auc)\n",
    "    \n",
    "    header = [\"Metric\", \"Test\"]\n",
    "    table  = [\n",
    "               [\"logloss\",   logloss_test],\n",
    "               [\"accuracy\",  accuracy_test],\n",
    "               [\"precision\", precision_test],\n",
    "               [\"F1\",        F1_test],\n",
    "               [\"r2\",        r2_test],\n",
    "               [\"AUC\",       auc_test]\n",
    "             ]\n",
    "\n",
    "    print(tabulate(table, header, tablefmt=\"fancy_grid\"))\n",
    "def Plot_predictor_importance(best_model, feature_columns):\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    y_pos  = np.arange(sorted_idx.shape[0]) + 100\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(y_pos, \n",
    "            feature_importance[sorted_idx], \n",
    "            align='center', \n",
    "            color='green', \n",
    "            ecolor='black', \n",
    "            height=0.5)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(feature_columns)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_title('Predictor Importance')\n",
    "    plt.show()\n",
    "\n",
    "def Report_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "def Print_confusion_matrix(cm, auc, heading):\n",
    "    print('\\n', heading)\n",
    "    print(cm)\n",
    "    true_negative  = cm[0,0]\n",
    "    true_positive  = cm[1,1]\n",
    "    false_negative = cm[1,0]\n",
    "    false_positive = cm[0,1]\n",
    "    total = true_negative + true_positive + false_negative + false_positive\n",
    "    accuracy = (true_positive + true_negative)/total\n",
    "    precision = (true_positive)/(true_positive + false_positive)\n",
    "    recall = (true_positive)/(true_positive + false_negative)\n",
    "    misclassification_rate = (false_positive + false_negative)/total\n",
    "    F1 = (2*true_positive)/(2*true_positive + false_positive + false_negative)\n",
    "    print('accuracy.................%7.4f' % accuracy)\n",
    "    print('precision................%7.4f' % precision)\n",
    "    print('recall...................%7.4f' % recall)\n",
    "    print('F1.......................%7.4f' % F1)\n",
    "    print('auc......................%7.4f' % auc)\n",
    "def Plot_learning_curve(estimator, title, X, y, ylim = None, cv = None,\n",
    "                        n_jobs = 1, train_sizes = np.linspace(0.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, \n",
    "                                                            X, y,\n",
    "                                                            cv = cv,\n",
    "                                                            n_jobs = n_jobs,\n",
    "                                                            train_sizes = train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    return\n",
    "def Random_Search():\n",
    "    global best_model, saved_moldel\n",
    "    \n",
    "    param_grid = {\"n_estimators\": range(20, 100, 2),\n",
    "                  \"max_depth\": range(4, 50, 2),\n",
    "                  \"min_samples_leaf\": range(2, 100, 2),\n",
    "                  \"max_features\": sp_randint(1, n_features),\n",
    "                  \"min_samples_split\": sp_randint(2, 10),\n",
    "                  \"bootstrap\": [True, False],\n",
    "                  \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "    clf = RandomForestClassifier(class_weight = 'balanced')\n",
    "    n_iter_search = 500\n",
    "    estimator = RandomizedSearchCV(clf,\n",
    "                                   param_distributions = param_grid,\n",
    "                                   n_iter = n_iter_search,\n",
    "                                   scoring = 'roc_auc',\n",
    "                                   verbose = 0,\n",
    "                                   n_jobs = 1)\n",
    "        \n",
    "    fit = estimator.fit(X_train, y_train)\n",
    "\n",
    "    # Cross validation with 20 iterations to get smoother mean test and train\n",
    "    # score curves, each time with 20% data randomly selected as a validation set.\n",
    "    cv_ = ShuffleSplit(n_splits = 20, test_size = 0.20, random_state = 0)\n",
    "    Plot_learning_curve(estimator, \n",
    "                        'Learning Curves',\n",
    "                        X_train, y_train, \n",
    "                        cv = cv_,\n",
    "                        n_jobs = 1)\n",
    "     \n",
    "    Report_scores(estimator.cv_results_, n_top = 3)\n",
    "    \n",
    "    best_model = estimator.best_estimator_\n",
    "    print('\\nbest_model:\\n', best_model)\n",
    "\n",
    "    print('\\nFeature Importances:', best_model.feature_importances_)\n",
    "    Plot_predictor_importance(best_model, feature_columns)\n",
    "\n",
    "    y_predicted = best_model.predict(X_train)\n",
    "    probabilities = best_model.predict_proba(X_train)\n",
    "\n",
    "    c_report = classification_report(y_train, y_predicted)\n",
    "    print('\\nClassification report:\\n', c_report)\n",
    "\n",
    "    y_predicted_train = best_model.predict(X_train)\n",
    "    cm = confusion_matrix(y_train, y_predicted_train)\n",
    "    auc = roc_auc_score(y_train, y_predicted_train)\n",
    "    Print_confusion_matrix(cm, auc, 'Confusion matrics of the training dataset')\n",
    "\n",
    "    y_predicted = best_model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    auc = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "    ntotal = len(y_test)\n",
    "    correct = y_test == y_predicted\n",
    "    numCorrect = sum(correct)\n",
    "    percent = round( (100.0*numCorrect)/ntotal, 6)\n",
    "    print(\"\\nCorrect classifications on test data: {0:d}/{1:d} {2:8.3f}%\".format(numCorrect, ntotal, percent))\n",
    "    prediction_score = 100.0*best_model.score(X_test, y_test)\n",
    "    print('Random Forest Prediction Score on test data: %8.3f' % prediction_score)\n",
    "\n",
    "    model_path = 'C:/sm/BottleRockets/trained_models/sklearn_rf_classify.pkl'\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "    saved_model = joblib.load(model_path)\n",
    "    y_predicted_test = best_model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_predicted_test)\n",
    "    auc = roc_auc_score(y_test, y_predicted_test)\n",
    "    Print_confusion_matrix(cm, auc, 'Confusion matrics of the test dataset')\n",
    "    ROC_Curve(best_model, auc)\n",
    "    Print_Metrics(saved_model)\n",
    "    return\n",
    "\n",
    "LoadData()\n",
    "Random_Search()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 28, 'max_features': 3, 'min_samples_leaf': 68, 'min_samples_split': 4, 'n_estimators': 22}\n",
    "\n",
    "\n",
    "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 38, 'max_features': 2, 'min_samples_leaf': 46, 'min_samples_split': 2, 'n_estimators': 20}\n",
    "\n",
    "\n",
    "\n",
    "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 32, 'max_features': 1, 'min_samples_leaf': 28, 'min_samples_split': 2, 'n_estimators': 68}\n",
    "\n",
    "\n",
    "\n",
    "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "        criterion='entropy', max_depth=28, max_features=3,\n",
    "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "            min_impurity_split=None, min_samples_leaf=68,\n",
    "            min_samples_split=4, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=22, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
